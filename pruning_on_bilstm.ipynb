{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnvvdW9CN0BJ/39pgFmt2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemant9785/deep-learning-/blob/main/pruning_on_bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtwSMfqeQuC"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# # Load the MNIST dataset\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# # Preprocess the data\n",
        "# num_classes = 10\n",
        "# input_shape = (28, 28)\n",
        "\n",
        "# x_train = x_train.reshape(-1, *input_shape).astype(\"float32\") / 255.0\n",
        "# x_test = x_test.reshape(-1, *input_shape).astype(\"float32\") / 255.0\n",
        "\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# # Build the BiLSTM model\n",
        "# model = keras.Sequential()\n",
        "# InputLayer = tf.keras.Input(shape=input_shape)\n",
        "# # Forward LSTM layer\n",
        "# model.add(InputLayer)\n",
        "# FW1 = layers.LSTM(28, return_sequences=True)\n",
        "# model.add(FW1)\n",
        "# # Backward LSTM layer\n",
        "# BW1= layers.LSTM(28, return_sequences=True, go_backwards=True)\n",
        "# model.add(BW1)\n",
        "# BL1 = layers.Bidirectional(FW1,merge_mode='ave',backward_layer=BW1)(InputLayer)\n",
        "# # Merge forward and backward layers\n",
        "# model.add(layers.Bidirectional())\n",
        "# # Output layer\n",
        "# model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# # Train the model\n",
        "# batch_size = 128\n",
        "# epochs = 10\n",
        "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# # Evaluate the model\n",
        "# _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "# print(\"Test accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "num_classes = 10\n",
        "input_shape = (28, 28)\n",
        "\n",
        "x_train = x_train.reshape(-1, *input_shape).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, *input_shape).astype(\"float32\") / 255.0\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Build the BiLSTM model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Forward LSTM layer\n",
        "model.add(layers.LSTM(28, return_sequences=True, input_shape=input_shape))\n",
        "# Backward LSTM layer\n",
        "model.add(layers.LSTM(28, return_sequences=True, go_backwards=True))\n",
        "# Merge forward and backward layers\n",
        "model.add(layers.Bidirectional(layers.LSTM(28, return_sequences=True), merge_mode='ave'))\n",
        "# Flatten the output\n",
        "model.add(layers.Flatten())\n",
        "# Output layer\n",
        "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "_, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLKEDna8eViw",
        "outputId": "75d62c6a-1811-401c-8d45-9d2fc320799f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "422/422 [==============================] - 33s 55ms/step - loss: 0.6170 - accuracy: 0.7961 - val_loss: 0.1725 - val_accuracy: 0.9435\n",
            "Epoch 2/3\n",
            "422/422 [==============================] - 22s 52ms/step - loss: 0.1531 - accuracy: 0.9526 - val_loss: 0.1009 - val_accuracy: 0.9697\n",
            "Epoch 3/3\n",
            "422/422 [==============================] - 23s 54ms/step - loss: 0.1057 - accuracy: 0.9668 - val_loss: 0.0872 - val_accuracy: 0.9740\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0881 - accuracy: 0.9697\n",
            "Test accuracy: 0.9696999788284302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "dD2_WWM5gmd4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install tensorflow_model_optimization"
      ],
      "metadata": {
        "id": "gC-JhoRtg0xS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import load_model\n",
        "# from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# # Custom wrapper layer for Bidirectional layer\n",
        "# class PrunableBidirectional(tf.keras.layers.Layer, sparsity.PrunableLayer):\n",
        "#     def __init__(self, layer, **kwargs):\n",
        "#         super(PrunableBidirectional, self).__init__(**kwargs)\n",
        "#         self.layer = layer\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.layer.build(input_shape)\n",
        "#         self.built = True\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         return self.layer(inputs)\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return self.layer.compute_output_shape(input_shape)\n",
        "\n",
        "#     def get_config(self):\n",
        "#         return self.layer.get_config()\n",
        "\n",
        "#     def get_prunable_weights(self):\n",
        "#         return self.layer.forward_layer._trainable_weights  + self.layer.backward_layer._trainable_weights \n",
        "\n",
        "# # Load the saved model\n",
        "# model = load_model('model.h5')\n",
        "\n",
        "# # Wrap the Bidirectional layer with PrunableBidirectional\n",
        "# prunable_model = tf.keras.Sequential()\n",
        "# for layer in model.layers:\n",
        "#     if isinstance(layer, tf.keras.layers.Bidirectional):\n",
        "#         prunable_model.add(PrunableBidirectional(layer))\n",
        "#     else:\n",
        "#         prunable_model.add(layer)\n",
        "\n",
        "# # Define the pruning parameters\n",
        "# pruning_params = {\n",
        "#     'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.90, begin_step=0, end_step=2000)\n",
        "# }\n",
        "\n",
        "# # Apply pruning to the model\n",
        "# pruned_model = sparsity.prune_low_magnitude(prunable_model, **pruning_params)\n",
        "\n",
        "# # Compile the pruned model\n",
        "# pruned_model.compile(\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     optimizer=\"adam\",\n",
        "#     metrics=[\"accuracy\"]\n",
        "# )\n",
        "\n",
        "# # Train the pruned model (optional)\n",
        "# pruned_model.fit(x_train, y_train, batch_size=128, epochs=1, validation_split=0.1)\n",
        "\n",
        "# # Save the pruned model\n",
        "# pruned_model.save('pruned_model.h5')\n"
      ],
      "metadata": {
        "id": "-mbevOLBhzKL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# Custom wrapper layer for Bidirectional layer\n",
        "class PrunableBidirectional(tf.keras.layers.Layer, sparsity.PrunableLayer):\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(PrunableBidirectional, self).__init__(**kwargs)\n",
        "        self.layer = layer\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.layer.build(input_shape)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layer(inputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return self.layer.compute_output_shape(input_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        return self.layer.get_config()\n",
        "\n",
        "    def get_prunable_weights(self):\n",
        "        return self.layer.forward_layer._trainable_weights + self.layer.backward_layer._trainable_weights\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# Wrap the Bidirectional layer with PrunableBidirectional\n",
        "prunable_model = tf.keras.Sequential()\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Bidirectional):\n",
        "        prunable_model.add(PrunableBidirectional(layer))\n",
        "    else:\n",
        "        prunable_model.add(layer)\n",
        "\n",
        "# Define the pruning parameters\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.90, begin_step=0, end_step=2000)\n",
        "}\n",
        "\n",
        "# Apply pruning to the model\n",
        "pruned_model = sparsity.prune_low_magnitude(prunable_model, **pruning_params)\n",
        "\n",
        "# Define the pruning callbacks\n",
        "callbacks = [\n",
        "    sparsity.UpdatePruningStep(),\n",
        "]\n",
        "\n",
        "# Compile the pruned model\n",
        "pruned_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the pruned model\n",
        "pruned_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the pruned model\n",
        "# pruned_model.save('pruned_model2.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0SNDpS9iktT",
        "outputId": "8948686d-a6fe-465c-ba0d-ffeb924ecbf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "422/422 [==============================] - 31s 55ms/step - loss: 0.1228 - accuracy: 0.9612 - val_loss: 0.1254 - val_accuracy: 0.9625\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 22s 51ms/step - loss: 0.1443 - accuracy: 0.9553 - val_loss: 0.1247 - val_accuracy: 0.9645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f735c4a7070>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6rn_62vlZUM",
        "outputId": "f9fcb74a-c88c-4829-e194-7f058b515452"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 28, 28)            6384      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 28, 28)            6384      \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 28, 28)           12768     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,386\n",
            "Trainable params: 33,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBBRsBSynzEM",
        "outputId": "b632bdd1-c33b-4aec-f32a-175858473b84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_lstm (P  (None, 28, 28)           12659     \n",
            " runeLowMagnitude)                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_lstm_1   (None, 28, 28)           12659     \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_prunabl  (None, 28, 28)           12769     \n",
            " e_bidirectional_1 (PruneLow                                     \n",
            " Magnitude)                                                      \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 784)              1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dense (  (None, 10)               15692     \n",
            " PruneLowMagnitude)                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,780\n",
            "Trainable params: 33,386\n",
            "Non-trainable params: 20,394\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "# tfmot.sparsity.keras.prune_low_magnitude.summary_weights(pruned_model)\n",
        "import numpy as np\n",
        "\n",
        "# Iterate over the layers of the pruned model\n",
        "for layer in pruned_model.layers:\n",
        "    if isinstance(layer, PrunableBidirectional):\n",
        "        forward_weights = layer.layer.forward_layer.get_weights()\n",
        "        backward_weights = layer.layer.backward_layer.get_weights()\n",
        "        print(forward_weights)\n",
        "        print(1)\n",
        "        forward_sparsity = 1 - np.count_nonzero(forward_weights[0]) / forward_weights[0].size\n",
        "        backward_sparsity = 1 - np.count_nonzero(backward_weights[0]) / backward_weights[0].size\n",
        "        \n",
        "        print(\"Forward Layer Sparsity: {:.2f}%\".format(forward_sparsity * 100))\n",
        "        print(\"Backward Layer Sparsity: {:.2f}%\".format(backward_sparsity * 100))\n",
        "        print()\n",
        "    else:\n",
        "        weights = layer.get_weights()\n",
        "        if weights:\n",
        "            # print(weights)\n",
        "            sparsity = 1 - np.count_nonzero(weights[0]) / weights[0].size\n",
        "            print(\"Layer Sparsity: {:.2f}%\".format(sparsity * 100))\n",
        "            print()\n",
        "        else:\n",
        "            print(\"Layer has no trainable weights.\")\n",
        "            print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w44N_i-un5wy",
        "outputId": "d368dace-2900-41f1-829f-31ab5596af50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 0.        ,  0.        , -0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [-0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "        -0.24565847,  0.        ],\n",
            "       [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
            "         0.        ,  0.27681792],\n",
            "       ...,\n",
            "       [-0.28916886, -0.        , -0.        , ..., -0.        ,\n",
            "        -0.27141735,  0.        ],\n",
            "       [-0.        , -0.        ,  0.33018345, ...,  0.        ,\n",
            "        -0.        ,  0.28975338],\n",
            "       [-0.        ,  0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        ,  0.        ]], dtype=float32), array([[ 0.        ,  0.34553406, -0.        , ...,  0.        ,\n",
            "        -0.        ,  0.        ],\n",
            "       [ 0.27240983, -0.        , -0.        , ...,  0.        ,\n",
            "        -0.28138286, -0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.27839214,\n",
            "         0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.27253476,  0.        , ..., -0.        ,\n",
            "         0.37702015, -0.        ],\n",
            "       [-0.        , -0.        , -0.        , ...,  0.        ,\n",
            "        -0.        , -0.        ],\n",
            "       [-0.        ,  0.24032065, -0.        , ..., -0.        ,\n",
            "        -0.        , -0.        ]], dtype=float32), array([ 1.28677443e-01,  2.20481470e-01, -4.77994755e-02,  8.28028992e-02,\n",
            "        5.81368729e-02,  4.81523499e-02,  1.31033778e-01,  1.16834991e-01,\n",
            "        2.13815778e-01,  2.14339569e-01,  1.85181394e-01,  1.87701941e-01,\n",
            "        1.35149539e-01,  9.25451741e-02,  1.74082488e-01,  2.42676914e-01,\n",
            "        1.61328614e-01,  6.97866529e-02,  1.43644169e-01,  1.50323838e-01,\n",
            "        2.20947027e-01,  1.62272185e-01,  2.14034375e-02,  1.92924291e-01,\n",
            "        1.63816556e-01,  1.00568824e-01,  3.13277394e-01, -4.55441847e-02,\n",
            "        9.48449552e-01,  9.77299631e-01,  9.49689686e-01,  9.94114876e-01,\n",
            "        1.05186284e+00,  1.05535114e+00,  1.06459332e+00,  8.92741323e-01,\n",
            "        1.03724325e+00,  1.03103364e+00,  1.05215538e+00,  1.07650626e+00,\n",
            "        1.06433988e+00,  9.76435244e-01,  1.03061867e+00,  9.82443750e-01,\n",
            "        1.11996901e+00,  1.03179801e+00,  1.00173926e+00,  9.94711757e-01,\n",
            "        9.89904344e-01,  1.04717577e+00,  9.41935003e-01,  1.04322886e+00,\n",
            "        9.53956723e-01,  1.04250300e+00,  1.04782534e+00,  1.03332210e+00,\n",
            "       -4.32422385e-03,  6.81215972e-02, -5.91043830e-02, -6.73896968e-02,\n",
            "       -5.67430025e-03, -8.17680033e-04,  5.25946096e-02, -2.18959525e-03,\n",
            "        1.76602900e-02, -1.40237354e-03, -2.52591562e-03, -2.94619389e-02,\n",
            "       -1.79536473e-02,  1.92700513e-03,  2.09332071e-02, -7.17329234e-02,\n",
            "       -1.42488927e-02, -1.19207380e-02,  3.79074961e-02,  2.75636325e-03,\n",
            "       -1.53622199e-02, -3.01408675e-02,  1.70549937e-02, -3.96900624e-03,\n",
            "        1.79094728e-02, -4.63697314e-02,  2.49041915e-02, -3.56296338e-02,\n",
            "        1.86001912e-01,  3.06671262e-01,  9.16317031e-02,  9.78121236e-02,\n",
            "        1.46610901e-01,  1.63141221e-01,  1.43268719e-01,  2.19540671e-01,\n",
            "        1.95308298e-01,  2.27570713e-01,  1.76656142e-01,  2.47278199e-01,\n",
            "        1.42660022e-01,  1.16881296e-01,  1.96910396e-01,  2.85272956e-01,\n",
            "        1.25958830e-01,  7.68088698e-02,  6.36975095e-02,  1.92320064e-01,\n",
            "        2.33756781e-01,  3.05024832e-01,  6.77765831e-02,  2.19081864e-01,\n",
            "        9.58011672e-02,  1.50825500e-01,  4.05221164e-01,  8.37673992e-02],\n",
            "      dtype=float32)]\n",
            "Layer Sparsity: 81.35%\n",
            "\n",
            "[array([[-0.29888904,  0.4455998 ,  0.        , ..., -0.        ,\n",
            "        -0.        , -0.        ],\n",
            "       [-0.        ,  0.        ,  0.        , ..., -0.        ,\n",
            "        -0.38271236, -0.        ],\n",
            "       [ 0.27516615,  0.        , -0.        , ...,  0.57134604,\n",
            "         0.2873512 ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.        ,  0.31584203, ...,  0.        ,\n",
            "         0.24918799,  0.        ],\n",
            "       [ 0.30743086,  0.        , -0.29947406, ..., -0.41703585,\n",
            "        -0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.2661652 , ...,  0.        ,\n",
            "         0.        ,  0.33548152]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.27459064,\n",
            "        -0.        , -0.        ],\n",
            "       [-0.27988285,  0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        ,  0.23831035],\n",
            "       [ 0.3085699 ,  0.        ,  0.        , ..., -0.        ,\n",
            "        -0.        , -0.        ],\n",
            "       ...,\n",
            "       [-0.        , -0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        , -0.31870678],\n",
            "       [-0.17383604,  0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        , -0.        ],\n",
            "       [-0.        , -0.        , -0.        , ...,  0.        ,\n",
            "         0.2353319 ,  0.        ]], dtype=float32), array([ 9.35846120e-02,  9.61107910e-02,  1.41764730e-01,  1.61726296e-01,\n",
            "        1.83159754e-01,  6.02524504e-02,  1.34860396e-01,  1.64597139e-01,\n",
            "        1.84506565e-01,  1.59650117e-01,  1.06671810e-01,  9.72716138e-02,\n",
            "        1.63360104e-01,  8.63930359e-02,  1.30652308e-01,  8.96326676e-02,\n",
            "        1.98325574e-01,  1.06250703e-01,  8.99621025e-02,  1.68551877e-01,\n",
            "        1.40261784e-01,  3.33801955e-01,  1.31989345e-01,  1.21982142e-01,\n",
            "        3.49693745e-01,  1.34674594e-01,  1.52685091e-01,  1.54755324e-01,\n",
            "        1.00275469e+00,  1.05938542e+00,  1.01854241e+00,  1.04166555e+00,\n",
            "        1.02134287e+00,  9.87471104e-01,  9.81949270e-01,  9.70815241e-01,\n",
            "        1.03988326e+00,  9.96850967e-01,  1.03618228e+00,  1.05219281e+00,\n",
            "        1.06433225e+00,  1.06676197e+00,  1.03429759e+00,  9.80363131e-01,\n",
            "        1.02975345e+00,  9.94378507e-01,  9.94413972e-01,  1.02684510e+00,\n",
            "        1.07783401e+00,  1.03348720e+00,  1.02442646e+00,  1.04441047e+00,\n",
            "        1.11115944e+00,  9.98641491e-01,  9.75287378e-01,  9.87819433e-01,\n",
            "        1.34611940e-02,  3.02377157e-02,  1.59291911e-03,  3.75707112e-02,\n",
            "       -2.61540674e-02,  6.61259517e-03,  1.97198205e-02,  4.06856835e-02,\n",
            "        1.84785333e-02, -1.95796192e-02, -2.86450819e-03, -7.57878460e-03,\n",
            "       -2.74768681e-05, -1.64099019e-02, -1.88357569e-02, -1.54182743e-02,\n",
            "        6.66486332e-03, -2.52977815e-02,  4.05040309e-02,  4.56041731e-02,\n",
            "        1.37408543e-03,  2.12817849e-03,  4.07602713e-02,  5.09417895e-03,\n",
            "        1.85969267e-02, -1.04347253e-02,  5.32891676e-02,  2.13166233e-02,\n",
            "        1.18735686e-01,  1.68283477e-01,  2.38720849e-01,  1.88358188e-01,\n",
            "        2.45908022e-01,  6.71123415e-02,  1.06213398e-01,  1.62406012e-01,\n",
            "        1.71304792e-01,  1.30820423e-01,  1.81328535e-01,  1.46843120e-01,\n",
            "        1.99959412e-01,  1.56316832e-01,  1.06799863e-01,  1.02566361e-01,\n",
            "        1.84602782e-01,  5.57329655e-02,  9.57740545e-02,  1.55107334e-01,\n",
            "        2.10410163e-01,  3.16009223e-01,  1.24687746e-01,  1.55569106e-01,\n",
            "        2.90703118e-01,  1.92970917e-01,  2.19267294e-01,  1.49416164e-01],\n",
            "      dtype=float32)]\n",
            "Layer Sparsity: 81.35%\n",
            "\n",
            "[array([[-3.16489227e-02,  3.18199024e-02,  1.22649133e-01, ...,\n",
            "         1.39783621e-02, -2.08651684e-02, -7.82283619e-02],\n",
            "       [-2.82959137e-02,  3.44591797e-04,  5.37891805e-01, ...,\n",
            "        -2.67686933e-01, -5.77767193e-02,  1.19325519e-01],\n",
            "       [-9.71856192e-02, -3.27601254e-01,  3.65951210e-01, ...,\n",
            "        -3.29952762e-02, -2.45234847e-01,  8.21277425e-02],\n",
            "       ...,\n",
            "       [ 2.15575054e-01, -1.62425831e-01, -4.03183922e-02, ...,\n",
            "         7.90246725e-02, -2.11041480e-01, -7.78345987e-02],\n",
            "       [ 1.01260826e-01,  1.56382561e-01, -2.48799115e-01, ...,\n",
            "         2.36399159e-01, -1.40585288e-01, -1.14005335e-01],\n",
            "       [ 3.34935337e-01, -2.00708285e-01, -2.36562453e-02, ...,\n",
            "         2.39194497e-01,  1.27634630e-01,  1.50346681e-01]], dtype=float32), array([[ 0.03979547, -0.00492819, -0.16693014, ..., -0.0088969 ,\n",
            "        -0.14931129, -0.14499588],\n",
            "       [-0.06297561, -0.08775827, -0.10959468, ...,  0.22775249,\n",
            "         0.05559739,  0.23831335],\n",
            "       [-0.18470888, -0.1851655 , -0.22398624, ...,  0.13567774,\n",
            "         0.2847404 ,  0.00560585],\n",
            "       ...,\n",
            "       [-0.16466942, -0.06917278,  0.18911469, ..., -0.15738869,\n",
            "        -0.12956695, -0.15777558],\n",
            "       [-0.17108037,  0.23068939, -0.1945684 , ...,  0.2952047 ,\n",
            "         0.11697163,  0.23075922],\n",
            "       [ 0.05703323, -0.02892867,  0.11041997, ...,  0.05766845,\n",
            "        -0.01179272, -0.00268876]], dtype=float32), array([ 0.07494647,  0.11977779,  0.00830315,  0.10778353,  0.16888446,\n",
            "        0.15656666,  0.31081566,  0.23968697,  0.2574458 ,  0.255124  ,\n",
            "        0.14156093,  0.142215  ,  0.28004208,  0.15764132,  0.20921177,\n",
            "        0.2223886 ,  0.16599277,  0.18923388,  0.24761727,  0.14652516,\n",
            "        0.17401323,  0.07259248,  0.07374263,  0.12000712,  0.2330675 ,\n",
            "        0.09007984,  0.18196294,  0.11400705,  1.0021297 ,  1.0787193 ,\n",
            "        1.1219946 ,  1.1510296 ,  1.1599839 ,  1.0618258 ,  1.1097617 ,\n",
            "        1.0871899 ,  1.0229751 ,  1.0992643 ,  1.1187413 ,  1.1197227 ,\n",
            "        1.0740211 ,  1.0722114 ,  1.0183554 ,  1.1324469 ,  1.0387676 ,\n",
            "        1.087554  ,  1.0295409 ,  1.057473  ,  1.0776496 ,  1.0520608 ,\n",
            "        1.0373348 ,  0.99238884,  1.106596  ,  1.1343433 ,  1.0423106 ,\n",
            "        1.0670168 ,  0.01571954,  0.03674713,  0.04775186,  0.01540803,\n",
            "       -0.01688912,  0.02982759,  0.01506184, -0.0348327 ,  0.00416629,\n",
            "       -0.01261404, -0.02919273,  0.04053208,  0.01372604,  0.047553  ,\n",
            "       -0.02645548, -0.04587184, -0.01224434, -0.04993675,  0.03673219,\n",
            "       -0.05415918, -0.00161855,  0.04005734, -0.05377084, -0.02146651,\n",
            "        0.03277549,  0.02747992, -0.03559468,  0.00583461,  0.12878983,\n",
            "        0.18436076,  0.15938601,  0.10951659,  0.19555645,  0.13265039,\n",
            "        0.21401383,  0.2867933 ,  0.22839108,  0.27678403,  0.11942788,\n",
            "        0.1152477 ,  0.17059223,  0.19730537,  0.21401396,  0.2745568 ,\n",
            "        0.1634725 ,  0.12922838,  0.29352817,  0.10197157,  0.15086229,\n",
            "        0.1437221 ,  0.19663307,  0.06922957,  0.24316502,  0.26639673,\n",
            "        0.13025603,  0.14099221], dtype=float32), array([[ 0.23496681, -0.1136433 ,  0.3104808 , ..., -0.00209992,\n",
            "         0.1507028 ,  0.23209806],\n",
            "       [-0.14490466,  0.04445963,  0.11666999, ...,  0.02158872,\n",
            "         0.17511997,  0.14524662],\n",
            "       [-0.07037433,  0.04600503, -0.15360132, ..., -0.08888245,\n",
            "         0.28296962, -0.03174942],\n",
            "       ...,\n",
            "       [-0.1688655 , -0.02878006, -0.27944902, ...,  0.17198111,\n",
            "         0.15251873,  0.00049318],\n",
            "       [ 0.02739537,  0.30900848,  0.40893587, ..., -0.08274448,\n",
            "        -0.01932464, -0.10881812],\n",
            "       [ 0.18489245,  0.15105943, -0.0903033 , ...,  0.29502207,\n",
            "         0.02731299,  0.23321882]], dtype=float32), array([[ 0.09249071, -0.04770148,  0.17234142, ...,  0.10110279,\n",
            "         0.2793294 ,  0.04698205],\n",
            "       [-0.0367325 , -0.02589057, -0.1522109 , ..., -0.04157216,\n",
            "         0.04532687, -0.22534685],\n",
            "       [-0.20303144, -0.16944969, -0.11591252, ..., -0.07164813,\n",
            "        -0.18189433,  0.08122696],\n",
            "       ...,\n",
            "       [ 0.23661229,  0.08971936,  0.14651982, ...,  0.10041136,\n",
            "         0.1672474 ,  0.14226058],\n",
            "       [-0.12960412, -0.18007094,  0.20567137, ..., -0.13765448,\n",
            "        -0.08942503, -0.07429092],\n",
            "       [ 0.10496872,  0.14663377,  0.00144926, ...,  0.08693758,\n",
            "         0.38845652,  0.10441966]], dtype=float32), array([ 1.15801618e-01,  2.05323219e-01,  2.01625139e-01,  1.53356805e-01,\n",
            "        1.39640540e-01,  1.85302958e-01,  7.00985715e-02,  1.57942191e-01,\n",
            "        2.64895380e-01,  1.76471666e-01,  6.62492886e-02,  9.95128006e-02,\n",
            "        1.74183115e-01,  1.64828300e-01,  2.29935616e-01,  2.41767511e-01,\n",
            "        1.67931184e-01,  2.28871614e-01,  1.56134933e-01,  1.76286489e-01,\n",
            "        1.70600265e-01,  3.18895727e-01,  1.87476054e-01,  6.27552494e-02,\n",
            "        1.02680504e-01,  2.28141576e-01,  2.37724230e-01,  1.33275241e-01,\n",
            "        1.06118786e+00,  1.11860526e+00,  1.15572894e+00,  1.11067581e+00,\n",
            "        1.14944923e+00,  1.08928120e+00,  1.08718729e+00,  1.08823729e+00,\n",
            "        1.03247523e+00,  1.04491019e+00,  1.01788247e+00,  1.03270769e+00,\n",
            "        1.06130862e+00,  1.06392121e+00,  1.09796584e+00,  1.07391560e+00,\n",
            "        1.07057118e+00,  1.13969970e+00,  1.15982008e+00,  1.08916306e+00,\n",
            "        1.18859255e+00,  1.08248568e+00,  1.10044265e+00,  1.04750156e+00,\n",
            "        1.07624912e+00,  1.07174194e+00,  1.17626727e+00,  1.12487924e+00,\n",
            "        4.36693169e-02, -1.06275734e-02,  1.21460278e-02,  3.31356637e-02,\n",
            "       -2.22866796e-02, -4.45598215e-02,  2.22746469e-03, -3.21195740e-03,\n",
            "       -1.90001503e-02,  5.64592704e-03,  2.00714003e-02,  4.05748822e-02,\n",
            "        1.79698435e-03,  2.91385017e-02, -5.79613121e-03, -3.35660055e-02,\n",
            "       -4.75867372e-03, -5.03970459e-02,  4.08207737e-02, -2.21158564e-02,\n",
            "        2.95646973e-02,  2.88113672e-02, -2.09501639e-04, -1.40531864e-02,\n",
            "        3.01839244e-02, -1.93041265e-02,  7.52226356e-03,  4.22363617e-02,\n",
            "        1.32897764e-01,  2.15755969e-01,  2.22801208e-01,  2.53930032e-01,\n",
            "        2.16878161e-01,  1.93537265e-01,  2.71070182e-01,  2.40227401e-01,\n",
            "        2.88527071e-01,  1.60686299e-01,  1.62802830e-01,  1.03444211e-01,\n",
            "        2.69305915e-01,  2.51616120e-01,  3.17447871e-01,  2.06552535e-01,\n",
            "        2.12212771e-01,  1.16292089e-01,  1.70915827e-01,  2.47176811e-01,\n",
            "        2.25911424e-01,  2.61410028e-01,  2.64609426e-01,  1.46673039e-01,\n",
            "        1.85751751e-01,  2.81299651e-01,  2.72276849e-01,  1.11897998e-01],\n",
            "      dtype=float32)]\n",
            "Layer Sparsity: 0.00%\n",
            "\n",
            "Layer has no trainable weights.\n",
            "\n",
            "[array([[ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        ,  0.        ],\n",
            "       [-0.        , -0.        , -0.        , ...,  0.        ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.16846941,  0.        , -0.        , ..., -0.        ,\n",
            "         0.        , -0.        ],\n",
            "       [-0.        , -0.        , -0.        , ..., -0.        ,\n",
            "         0.        , -0.        ],\n",
            "       [-0.        , -0.        ,  0.        , ...,  0.        ,\n",
            "        -0.        , -0.        ]], dtype=float32), array([ 0.01263732,  0.09185508,  0.02390849, -0.02683469, -0.00239946,\n",
            "        0.02391684, -0.04823439, -0.00140422, -0.03877808, -0.01198597],\n",
            "      dtype=float32)]\n",
            "Layer Sparsity: 81.36%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfSDMdQXoRVx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}